{"id":"bd-1","title":"Feature: Skill Auto-Activation System with Hooks","description":"","design":"## Goal\nAdd comprehensive skill auto-activation system using hooks to ensure skills activate reliably and Claude stays on track during execution.\n\n## Chosen Approach\nModular hook system with three separate hooks (UserPromptSubmit, PostToolUse, Stop) sharing common utilities and skill-rules.json configuration. Shell-based implementation in hooks/ directory at plugin root.\n\n## Success Criteria\n- [ ] All phases complete\n- [ ] skill-rules.json defines rules for all hyperpowers skills\n- [ ] Three hooks implemented and tested\n- [ ] Integration tests passing\n- [ ] Documentation updated\n- [ ] User installation guide created","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-10-30T13:56:46.874868-04:00","updated_at":"2025-10-30T15:44:50.994123-04:00","closed_at":"2025-10-30T15:44:50.994123-04:00"}
{"id":"bd-2","title":"Phase 1: Skill Rules Configuration","description":"","design":"## Goal\nCreate skill-rules.json configuration defining triggers for all hyperpowers skills.\n\n## Effort Estimate\n6-8 hours\n\n## Success Criteria\n- [ ] skill-rules.json created with valid JSON (verified with jq . skill-rules.json)\n- [ ] All hyperpowers skills have defined rules (19 skills confirmed)\n- [ ] Each skill has 3-8 keywords and 2-5 intent patterns\n- [ ] Priority levels appropriately assigned (max 3-4 critical skills)\n- [ ] JSON validates successfully with jq\n- [ ] No regex patterns fail catastrophic backtracking test\n- [ ] Sample prompts match expected skills (90%+ accuracy on test set)\n- [ ] File size under 50KB\n- [ ] Documentation comments explain each pattern's purpose\n\n## Implementation Steps (ADDED BY writing-plans)\n\n### Step Group 1: Initial Setup and Skill Inventory\n\n**Files:**\n- Create: hooks/skill-rules.json\n- Reference: skills/skills-auto-activation/resources/skill-rules-examples.md\n\n**Step 1: Count and list all skills**\n\nRun:\n```bash\ncd /Users/ryan/src/hyper\nls -1 skills/*/SKILL.md | wc -l\n```\nExpected: 19 skills\n\n**Step 2: Extract all skill names for reference**\n\nRun:\n```bash\ncd /Users/ryan/src/hyper\nfor skill in skills/*/SKILL.md; do \n  dirname \"$skill\" | sed 's|skills/||'\ndone | sort\n```\nExpected output: List of 19 skills (brainstorming through writing-skills)\n\n### Step Group 2: Create Core Configuration Structure\n\n**Step 3: Create initial skill-rules.json with schema documentation**\n\nCreate hooks/skill-rules.json:\n```json\n{\n  \"_comment\": \"Skill activation rules for hyperpowers plugin - 19 skills total\",\n  \"_schema\": {\n    \"description\": \"Each skill has type, enforcement, priority, and triggers\",\n    \"type\": \"process|domain|workflow\", \n    \"enforcement\": \"suggest\",\n    \"priority\": \"critical|high|medium|low\",\n    \"promptTriggers\": {\n      \"keywords\": \"Array of case-insensitive strings\",\n      \"intentPatterns\": \"Array of regex patterns for action+object\"\n    }\n  }\n}\n```\n\n**Step 4: Verify JSON syntax**\n\nRun:\n```bash\ncd /Users/ryan/src/hyper\njq . hooks/skill-rules.json\n```\nExpected: Valid JSON output with formatted structure\n\n### Step Group 3: Add Core Workflow Skills (5 skills)\n\n**Step 5: Add test-driven-development skill rules**\n\nAdd to hooks/skill-rules.json:\n```json\n\"test-driven-development\": {\n  \"type\": \"process\",\n  \"enforcement\": \"suggest\",\n  \"priority\": \"critical\",\n  \"promptTriggers\": {\n    \"keywords\": [\"test\", \"testing\", \"TDD\", \"spec\", \"unit test\", \"integration test\", \"test first\", \"red green refactor\"],\n    \"intentPatterns\": [\n      \"(write|add|create|implement).*?(test|spec|unit test)\",\n      \"test.*(first|before|driven)\",\n      \"(implement|build|create).*?(feature|function|component)\",\n      \"red.*(green|refactor)\",\n      \"(bug|fix|issue).*?reproduce\"\n    ]\n  }\n}\n```\n\n**Step 6: Add debugging-with-tools skill rules**\n\nAdd to hooks/skill-rules.json:\n```json\n\"debugging-with-tools\": {\n  \"type\": \"process\",\n  \"enforcement\": \"suggest\",\n  \"priority\": \"high\",\n  \"promptTriggers\": {\n    \"keywords\": [\"debug\", \"debugging\", \"error\", \"bug\", \"crash\", \"fails\", \"broken\", \"not working\", \"issue\"],\n    \"intentPatterns\": [\n      \"(debug|fix|solve|investigate|troubleshoot).*?(error|bug|issue|problem)\",\n      \"(why|what).*?(failing|broken|not working|crashing)\",\n      \"(find|locate|identify).*?(bug|issue|problem|root cause)\",\n      \"reproduce.*(bug|issue|error)\",\n      \"stack.*(trace|error)\"\n    ]\n  }\n}\n```\n\n**Step 7: Add refactoring-safely skill rules**\n\nAdd to hooks/skill-rules.json:\n```json\n\"refactoring-safely\": {\n  \"type\": \"process\",\n  \"enforcement\": \"suggest\",\n  \"priority\": \"medium\",\n  \"promptTriggers\": {\n    \"keywords\": [\"refactor\", \"refactoring\", \"cleanup\", \"improve\", \"restructure\", \"reorganize\", \"simplify\"],\n    \"intentPatterns\": [\n      \"(refactor|clean up|improve|restructure).*?(code|function|class|component)\",\n      \"(extract|split|separate).*?(function|method|component|logic)\",\n      \"(rename|move|relocate).*?(file|function|class)\",\n      \"remove.*(duplication|duplicate|repeated code)\"\n    ]\n  }\n}\n```\n\n**Step 8: Add fixing-bugs skill rules**\n\nAdd to hooks/skill-rules.json:\n```json\n\"fixing-bugs\": {\n  \"type\": \"process\",\n  \"enforcement\": \"suggest\",\n  \"priority\": \"high\",\n  \"promptTriggers\": {\n    \"keywords\": [\"bug\", \"fix\", \"issue\", \"problem\", \"defect\", \"regression\"],\n    \"intentPatterns\": [\n      \"(fix|resolve|solve).*?(bug|issue|problem|defect)\",\n      \"(bug|issue|problem).*(report|ticket|found)\",\n      \"regression.*(test|fix|found)\",\n      \"(broken|not working).*(fix|repair)\"\n    ]\n  }\n}\n```\n\n**Step 9: Add root-cause-tracing skill rules**\n\nAdd to hooks/skill-rules.json:\n```json\n\"root-cause-tracing\": {\n  \"type\": \"process\",\n  \"enforcement\": \"suggest\",\n  \"priority\": \"medium\",\n  \"promptTriggers\": {\n    \"keywords\": [\"root cause\", \"trace\", \"origin\", \"source\", \"why\", \"deep dive\"],\n    \"intentPatterns\": [\n      \"root.*(cause|problem|issue)\",\n      \"trace.*(back|origin|source)\",\n      \"(why|how).*(happening|occurring|caused)\",\n      \"deep.*(dive|analysis|investigation)\"\n    ]\n  }\n}\n```\n\n### Step Group 4: Add Planning \u0026 Execution Skills (8 skills)\n\n**Step 10: Add brainstorming skill rules**\n\nAdd to hooks/skill-rules.json:\n```json\n\"brainstorming\": {\n  \"type\": \"workflow\",\n  \"enforcement\": \"suggest\",\n  \"priority\": \"high\",\n  \"promptTriggers\": {\n    \"keywords\": [\"plan\", \"design\", \"architecture\", \"approach\", \"brainstorm\", \"idea\", \"feature\", \"implement\"],\n    \"intentPatterns\": [\n      \"(create|build|add|implement).*?(feature|system|component|functionality)\",\n      \"(how should|what's the best way|how to).*?(implement|build|design)\",\n      \"I want to.*(add|create|build|implement)\",\n      \"(plan|design|architect).*?(system|feature|component)\",\n      \"let's.*(think|plan|design)\"\n    ]\n  }\n}\n```\n\n**Step 11: Add writing-plans skill rules**\n\nAdd to hooks/skill-rules.json:\n```json\n\"writing-plans\": {\n  \"type\": \"workflow\",\n  \"enforcement\": \"suggest\",\n  \"priority\": \"high\",\n  \"promptTriggers\": {\n    \"keywords\": [\"expand\", \"enhance\", \"detailed steps\", \"implementation steps\", \"bd tasks\"],\n    \"intentPatterns\": [\n      \"expand.*?(bd|task|plan)\",\n      \"enhance.*?with.*(steps|details)\",\n      \"add.*(implementation|detailed).*(steps|instructions)\",\n      \"write.*?plan\"\n    ]\n  }\n}\n```\n\n**Step 12: Add executing-plans skill rules**\n\nAdd to hooks/skill-rules.json:\n```json\n\"executing-plans\": {\n  \"type\": \"workflow\",\n  \"enforcement\": \"suggest\",\n  \"priority\": \"high\",\n  \"promptTriggers\": {\n    \"keywords\": [\"execute\", \"implement\", \"start working\", \"begin implementation\", \"work on bd\"],\n    \"intentPatterns\": [\n      \"execute.*(plan|tasks|bd)\",\n      \"(start|begin).*(implementation|work|executing)\",\n      \"implement.*?bd-\\\\d+\",\n      \"work.*?on.*(tasks|bd|plan)\"\n    ]\n  }\n}\n```\n\n**Step 13: Add remaining planning skills**\n\nAdd review-implementation, finishing-a-development-branch, sre-task-refinement, managing-bd-tasks with similar patterns.\n\n### Step Group 5: Add Quality \u0026 Infrastructure Skills (6 skills)\n\n**Step 14: Add verification-before-completion skill rules**\n\nAdd to hooks/skill-rules.json:\n```json\n\"verification-before-completion\": {\n  \"type\": \"process\",\n  \"enforcement\": \"suggest\",\n  \"priority\": \"critical\",\n  \"promptTriggers\": {\n    \"keywords\": [\"done\", \"complete\", \"finished\", \"ready\", \"verified\", \"works\", \"passing\"],\n    \"intentPatterns\": [\n      \"(I'm|it's|work is).*(done|complete|finished)\",\n      \"(ready|prepared).*(merge|commit|push|PR)\",\n      \"everything.*(works|passes|ready)\",\n      \"(verified|tested|checked).*?(everything|all)\",\n      \"can we.*(merge|commit|ship)\"\n    ]\n  }\n}\n```\n\n**Step 15: Add remaining quality and infrastructure skills**\n\nAdd dispatching-parallel-agents, building-hooks, skills-auto-activation, testing-anti-patterns, using-hyper, writing-skills with appropriate patterns.\n\n### Step Group 6: Test and Validate Configuration\n\n**Step 16: Validate complete JSON file**\n\nRun:\n```bash\ncd /Users/ryan/src/hyper\njq . hooks/skill-rules.json \u003e /dev/null \u0026\u0026 echo \"✓ Valid JSON\" || echo \"✗ Invalid JSON\"\n```\nExpected: ✓ Valid JSON\n\n**Step 17: Check file size**\n\nRun:\n```bash\nls -lh hooks/skill-rules.json | awk '{print $5}'\n```\nExpected: \u003c 50KB (should be around 15-20KB)\n\n**Step 18: Count skills in configuration**\n\nRun:\n```bash\njq 'keys - [\"_comment\", \"_schema\"] | length' hooks/skill-rules.json\n```\nExpected: 19\n\n**Step 19: Test keyword matching with sample prompts**\n\nCreate test script:\n```bash\n#!/bin/bash\n# Test skill activation patterns\nprompt=\"I want to write a test for the login function\"\njq --arg prompt \"$prompt\" '\n  to_entries | \n  map(select(.value.promptTriggers.keywords as $kw | \n    $prompt | ascii_downcase | \n    test($kw | map(. | ascii_downcase) | join(\"|\"))\n  )) | \n  map(.key)\n' hooks/skill-rules.json\n```\nExpected: Should match \"test-driven-development\"\n\n**Step 20: Commit the configuration**\n\nRun:\n```bash\ngit add hooks/skill-rules.json\ngit commit -m \"feat(bd-2): create skill-rules.json configuration\n\nImplements bd-2: Skill Rules Configuration\n- Defines activation rules for all 19 hyperpowers skills\n- Includes keywords and intent patterns for each skill\n- Sets appropriate priority levels (critical/high/medium/low)\n- Validated JSON syntax and file size \u003c 50KB\"\n```\n\n### Step Group 7: Document Pattern Testing\n\n**Step 21: Create regex testing documentation**\n\nCreate hooks/REGEX_TESTING.md:\n```markdown\n# Regex Pattern Testing for skill-rules.json\n\n## Tested Patterns\n\nAll regex patterns in skill-rules.json have been tested on regex101.com for:\n- Catastrophic backtracking (10000 'a's input)\n- Unicode handling\n- Performance\n\n### Test Results\n\n| Pattern | Backtracking Safe | Unicode Safe | Avg Time |\n|---------|------------------|--------------|----------|\n| (create|add).*?(feature|component) | ✓ | ✓ | \u003c1ms |\n| (debug|fix).*?(error|bug) | ✓ | ✓ | \u003c1ms |\n[... document all patterns ...]\n```\n\n**Step 22: Final validation**\n\nRun:\n```bash\ncd /Users/ryan/src/hyper\necho \"=== Skill Rules Validation ===\"\necho \"1. JSON valid: $(jq . hooks/skill-rules.json \u003e /dev/null 2\u003e\u00261 \u0026\u0026 echo '✓' || echo '✗')\"\necho \"2. Skill count: $(jq 'keys - [\"_comment\", \"_schema\"] | length' hooks/skill-rules.json) (expected: 19)\"\necho \"3. File size: $(ls -lh hooks/skill-rules.json | awk '{print $5}')\"\n```\nExpected: All validations pass\n\n## Key Considerations (ADDED BY SRE REVIEW)\n- Pattern Design: Intent patterns should be broad enough to catch variations but specific enough to avoid false positives\n- Priority Balance: Don't overuse \"critical\" - reserve for verification and safety-critical workflows\n- Regex Performance: Keep patterns simple; avoid catastrophic backtracking\n- Maintenance: Document reasoning for each pattern to help future updates\n- File Size: Large JSON files can slow parsing - keep under 50KB\n- Testing Regex: MUST test all patterns on regex101.com with pathological inputs (10000 'a's)\n- Unicode Handling: Patterns should handle Unicode input gracefully\n- Case Sensitivity: All matching must be case-insensitive\n\n## Anti-patterns to Avoid\n- ❌ Overly broad keywords that match too many prompts (e.g., \"code\", \"file\", \"data\")\n- ❌ Complex regex patterns that are hard to maintain or have backtracking issues\n- ❌ Marking too many skills as \"critical\" priority (dilutes importance)\n- ❌ Missing common variations in intent patterns\n- ❌ Untested regex patterns (MUST test on regex101.com)\n- ❌ No comments explaining pattern intent\n- ❌ File size over 50KB (performance impact)","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-30T13:56:54.618233-04:00","updated_at":"2025-10-30T14:56:49.100685-04:00","closed_at":"2025-10-30T14:56:49.100685-04:00","dependencies":[{"issue_id":"bd-2","depends_on_id":"bd-1","type":"parent-child","created_at":"2025-10-30T13:57:10.44578-04:00","created_by":"ryan"}]}
{"id":"bd-3","title":"Phase 2: Shared Utility Functions","description":"","design":"## Goal\nBuild shared utility functions for skill matching and output formatting.\n\n## Effort Estimate  \n6-8 hours\n\n## Success Criteria\n- [ ] Both utility scripts created\n- [ ] Dependency checks implemented and tested\n- [ ] All functions implemented with proper error handling\n- [ ] Scripts fail gracefully if jq not installed (exit 1, clear error message)\n- [ ] Functions can be tested independently\n- [ ] All functions properly documented with comments\n- [ ] Handle empty/null inputs gracefully (return appropriate error code)\n- [ ] Handle malformed JSON gracefully (error message, exit 1)\n- [ ] Handle very long inputs (\u003e10KB) without hanging\n- [ ] Performance: match_keywords completes in \u003c50ms for typical input\n- [ ] Performance: find_matching_skills completes in \u003c200ms for 20 skills\n\n## Implementation Steps (ADDED BY writing-plans)\n\n### Step Group 1: Create Directory Structure\n\n**Files:**\n- Create: hooks/utils/skill-matcher.sh\n- Create: hooks/utils/format-output.sh\n\n**Step 1: Verify utils directory**\nRun:\n```bash\ncd /Users/ryan/src/hyper\nls -la hooks/utils/\n```\nExpected: Directory exists and is writable\n\n### Step Group 2: Create skill-matcher.sh Core Structure\n\n**Step 2: Create skill-matcher.sh with dependency checking**\nCreate hooks/utils/skill-matcher.sh:\n```bash\n#!/usr/bin/env bash\nset -e\n\ncheck_dependencies() {\n  local missing=()\n  command -v jq \u003e/dev/null 2\u003e\u00261 || missing+=(\"jq\")\n  command -v grep \u003e/dev/null 2\u003e\u00261 || missing+=(\"grep\")\n  \n  if [ ${#missing[@]} -gt 0 ]; then\n    echo \"ERROR: Missing required dependencies: ${missing[*]}\" \u003e\u00262\n    echo \"Please install missing tools and try again.\" \u003e\u00262\n    return 1\n  fi\n  return 0\n}\n\ncheck_dependencies || exit 1\n```\n\n**Step 3: Make executable**\nRun: `chmod +x hooks/utils/skill-matcher.sh`\n\n**Step 4: Test dependency checking**\nRun: `source hooks/utils/skill-matcher.sh \u0026\u0026 echo \"OK: $?\"`\nExpected: \"OK: 0\"\n\n### Step Group 3: Implement Skill Matcher Functions\n\n**Step 5: Add load_skill_rules function**\nAdd to skill-matcher.sh:\n```bash\nload_skill_rules() {\n  local rules_path=\"$1\"\n  \n  if [ -z \"$rules_path\" ]; then\n    echo \"ERROR: No rules path provided\" \u003e\u00262\n    return 1\n  fi\n  \n  if [ ! -f \"$rules_path\" ]; then\n    echo \"ERROR: Rules file not found: $rules_path\" \u003e\u00262\n    return 1\n  fi\n  \n  if ! jq . \"$rules_path\" 2\u003e/dev/null; then\n    echo \"ERROR: Invalid JSON in $rules_path\" \u003e\u00262\n    return 1\n  fi\n  \n  return 0\n}\n```\n\n**Step 6: Add match_keywords function**\nAdd to skill-matcher.sh:\n```bash\nmatch_keywords() {\n  local text=\"$1\"\n  local keywords=\"$2\"\n  \n  if [ -z \"$text\" ] || [ -z \"$keywords\" ]; then\n    return 1\n  fi\n  \n  local lower_text=$(echo \"$text\" | tr '[:upper:]' '[:lower:]')\n  \n  IFS=',' read -ra KEYWORD_ARRAY \u003c\u003c\u003c \"$keywords\"\n  for keyword in \"${KEYWORD_ARRAY[@]}\"; do\n    local lower_keyword=$(echo \"$keyword\" | tr '[:upper:]' '[:lower:]' | xargs)\n    if [[ \"$lower_text\" == *\"$lower_keyword\"* ]]; then\n      return 0\n    fi\n  done\n  \n  return 1\n}\n```\n\n**Step 7: Add match_patterns function**\nAdd to skill-matcher.sh:\n```bash\nmatch_patterns() {\n  local text=\"$1\"\n  local patterns=\"$2\"\n  \n  if [ -z \"$text\" ] || [ -z \"$patterns\" ]; then\n    return 1\n  fi\n  \n  local timeout_cmd=\"\"\n  if command -v timeout \u003e/dev/null 2\u003e\u00261; then\n    timeout_cmd=\"timeout 1\"\n  fi\n  \n  IFS=',' read -ra PATTERN_ARRAY \u003c\u003c\u003c \"$patterns\"\n  for pattern in \"${PATTERN_ARRAY[@]}\"; do\n    pattern=$(echo \"$pattern\" | xargs)\n    \n    if $timeout_cmd grep -Ei \"$pattern\" \u003c\u003c\u003c \"$text\" \u003e/dev/null 2\u003e\u00261; then\n      return 0\n    fi\n  done\n  \n  return 1\n}\n```\n\n**Step 8: Add find_matching_skills function**\nAdd complete function to match skills based on prompts, sorting by priority and limiting to top 3.\n\n**Step 9: Test functions**\nRun:\n```bash\nsource hooks/utils/skill-matcher.sh\nmatch_keywords \"I want to write a test\" \"test,testing,TDD\" \u0026\u0026 echo \"✓ Works\"\nmatch_patterns \"create a new feature\" \"(create|add).*?(feature|component)\" \u0026\u0026 echo \"✓ Works\"\nmatch_keywords \"\" \"test\" || echo \"✓ Empty handled\"\n```\nExpected: All pass\n\n### Step Group 4: Create format-output.sh\n\n**Step 10: Create format-output.sh with dependency checking**\nCreate hooks/utils/format-output.sh:\n```bash\n#!/usr/bin/env bash\nset -e\n\ncheck_dependencies() {\n  local missing=()\n  command -v jq \u003e/dev/null 2\u003e\u00261 || missing+=(\"jq\")\n  \n  if [ ${#missing[@]} -gt 0 ]; then\n    echo \"ERROR: Missing required dependencies: ${missing[*]}\" \u003e\u00262\n    return 1\n  fi\n  return 0\n}\n\ncheck_dependencies || exit 1\n\nget_priority_emoji() {\n  local priority=\"$1\"\n  case \"$priority\" in\n    \"critical\") echo \"🔴\" ;;\n    \"high\") echo \"⭐\" ;;\n    \"medium\") echo \"📌\" ;;\n    \"low\") echo \"💡\" ;;\n    *) echo \"•\" ;;\n  esac\n}\n```\n\n**Step 11: Add format_skill_reminder function**\nAdd function to format matched skills into activation reminder text.\n\n**Step 12: Add format_gentle_reminder function**\nAdd function for TDD, testing, and verification reminders.\n\n**Step 13: Make executable**\nRun: `chmod +x hooks/utils/format-output.sh`\n\n**Step 14: Test functions**\nRun:\n```bash\nsource hooks/utils/format-output.sh\n[ \"$(get_priority_emoji critical)\" = \"🔴\" ] \u0026\u0026 echo \"✓ Emoji works\"\nformat_gentle_reminder \"tdd\" | grep \"RED-GREEN-REFACTOR\" \u0026\u0026 echo \"✓ Reminder works\"\n```\n\n### Step Group 5: Performance Testing\n\n**Step 15: Create performance test**\nCreate hooks/utils/test-performance.sh to test match_keywords \u003c50ms and find_matching_skills \u003c200ms.\n\n**Step 16: Run performance tests**\nRun: `bash hooks/utils/test-performance.sh`\nExpected: Both under targets\n\n### Step Group 6: Validation and Testing\n\n**Step 17: Test edge cases**\nTest with empty inputs, malformed JSON, very long inputs (\u003e10KB).\n\n**Step 18: Commit utilities**\nRun:\n```bash\ngit add hooks/utils/skill-matcher.sh hooks/utils/format-output.sh\ngit commit -m \"feat(bd-3): create shared utility functions\n\nImplements bd-3: Shared Utility Functions\n- skill-matcher.sh with keyword/pattern matching\n- format-output.sh with formatting functions\n- Dependency checking for jq and grep\n- Performance optimized\n- Edge case handling\"\n```\n\n**Step 19-20: Create and run test suite**\nCreate comprehensive test suite and verify all tests pass.\n\n## Key Considerations (ADDED BY SRE REVIEW)\n- Dependency Failures: Scripts must fail immediately if jq not found\n- Error Messages: Clear, actionable error messages for missing deps\n- Pure Functions: No side effects, easy to test independently\n- JSON I/O: Use jq for all JSON operations\n- Error Handling: Functions return error codes, caller decides handling\n- Modularity: Each function does one thing well\n- Regex Timeout: Long regex can hang - consider GNU timeout wrapper if available\n- Input Validation: Check for empty/null inputs before processing\n- Output Escaping: Properly escape special characters in formatted output\n- Performance: Cache compiled regex patterns if possible\n- Large Input Handling: Gracefully handle prompts \u003e10KB\n\n## Anti-patterns to Avoid\n- ❌ Assuming dependencies are installed without checking\n- ❌ Silent failures when dependencies missing\n- ❌ Functions with side effects (writing files, modifying globals)\n- ❌ Complex regex that's hard to debug or has catastrophic backtracking\n- ❌ Hardcoded paths instead of using parameters\n- ❌ No input validation (empty strings, null values)\n- ❌ No timeout protection for regex operations\n- ❌ Unbounded memory usage for large inputs","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-30T13:57:03.276093-04:00","updated_at":"2025-10-30T15:00:23.673747-04:00","closed_at":"2025-10-30T15:00:23.673747-04:00","dependencies":[{"issue_id":"bd-3","depends_on_id":"bd-1","type":"parent-child","created_at":"2025-10-30T13:57:10.461298-04:00","created_by":"ryan"},{"issue_id":"bd-3","depends_on_id":"bd-2","type":"blocks","created_at":"2025-10-30T13:57:16.81907-04:00","created_by":"ryan"}]}
{"id":"bd-4","title":"Phase 3: UserPromptSubmit Hook (Skill Activator)","description":"","design":"## Goal\nImplement hook that analyzes prompts and injects skill activation reminders.\n\n## Effort Estimate\n6-8 hours\n\n## Success Criteria\n- [ ] UserPromptSubmit hook created and configured in hooks.json\n- [ ] Hook analyzes prompts using skill-rules.json patterns\n- [ ] Top 3 matching skills injected as additionalContext\n- [ ] Priority-based sorting (critical \u003e high \u003e medium \u003e low)\n- [ ] Hook handles errors gracefully (always returns decision: continue)\n- [ ] Performance: \u003c100ms for typical prompt analysis\n- [ ] Manual testing with 5 sample prompts shows correct skill activation\n- [ ] Hook doesn't block or crash on malformed input\n\n## Implementation Steps (ADDED BY writing-plans)\n\n### Step Group 1: Create Hook Directory and Script\n\n**Files:**\n- Create: hooks/user-prompt-submit/10-skill-activator.js\n- Modify: hooks/hooks.json\n\n**Step 1: Create user-prompt-submit directory**\n\nRun:\n\\`\\`\\`bash\nmkdir -p hooks/user-prompt-submit\n\\`\\`\\`\n\n**Step 2: Create the skill-activator hook script**\n\nCreate \\`hooks/user-prompt-submit/10-skill-activator.js\\`:\n\n\\`\\`\\`javascript\n#!/usr/bin/env node\n\nconst fs = require('fs');\nconst path = require('path');\n\n// Configuration\nconst CONFIG = {\n    rulesPath: path.join(__dirname, '..', 'skill-rules.json'),\n    maxSkills: 3,  // Limit to top 3 to avoid context overload\n    debugMode: process.env.DEBUG_HOOKS === 'true'\n};\n\n// Load skill rules from skill-rules.json\nfunction loadRules() {\n    try {\n        const content = fs.readFileSync(CONFIG.rulesPath, 'utf8');\n        const data = JSON.parse(content);\n        // Filter out _comment and _schema meta keys\n        const rules = {};\n        for (const [key, value] of Object.entries(data)) {\n            if (!key.startsWith('_')) {\n                rules[key] = value;\n            }\n        }\n        return rules;\n    } catch (error) {\n        if (CONFIG.debugMode) {\n            console.error('Failed to load skill rules:', error.message);\n        }\n        return {};\n    }\n}\n\n// Read prompt from stdin (Claude passes { \"text\": \"...\" })\nfunction readPrompt() {\n    return new Promise((resolve) =\u003e {\n        let data = '';\n        process.stdin.on('data', chunk =\u003e data += chunk);\n        process.stdin.on('end', () =\u003e {\n            try {\n                resolve(JSON.parse(data));\n            } catch (error) {\n                if (CONFIG.debugMode) {\n                    console.error('Failed to parse prompt:', error.message);\n                }\n                resolve({ text: '' });\n            }\n        });\n    });\n}\n\n// Analyze prompt for skill matches\nfunction analyzePrompt(promptText, rules) {\n    const lowerText = promptText.toLowerCase();\n    const activated = [];\n\n    for (const [skillName, config] of Object.entries(rules)) {\n        let matched = false;\n        let matchReason = '';\n\n        // Check keyword triggers (case-insensitive substring matching)\n        if (config.promptTriggers?.keywords) {\n            for (const keyword of config.promptTriggers.keywords) {\n                if (lowerText.includes(keyword.toLowerCase())) {\n                    matched = true;\n                    matchReason = \\`keyword: \"\\${keyword}\"\\`;\n                    break;\n                }\n            }\n        }\n\n        // Check intent pattern triggers (regex matching)\n        if (!matched \u0026\u0026 config.promptTriggers?.intentPatterns) {\n            for (const pattern of config.promptTriggers.intentPatterns) {\n                try {\n                    if (new RegExp(pattern, 'i').test(promptText)) {\n                        matched = true;\n                        matchReason = \\`intent pattern: \"\\${pattern}\"\\`;\n                        break;\n                    }\n                } catch (error) {\n                    if (CONFIG.debugMode) {\n                        console.error(\\`Invalid pattern \"\\${pattern}\":\\`, error.message);\n                    }\n                }\n            }\n        }\n\n        if (matched) {\n            activated.push({\n                skill: skillName,\n                priority: config.priority || 'medium',\n                reason: matchReason,\n                type: config.type || 'workflow'\n            });\n        }\n    }\n\n    // Sort by priority (critical \u003e high \u003e medium \u003e low)\n    const priorityOrder = { critical: 0, high: 1, medium: 2, low: 3 };\n    activated.sort((a, b) =\u003e {\n        const priorityDiff = priorityOrder[a.priority] - priorityOrder[b.priority];\n        if (priorityDiff !== 0) return priorityDiff;\n        // Secondary sort: process types before domain/workflow types\n        const typeOrder = { process: 0, domain: 1, workflow: 2 };\n        return (typeOrder[a.type] || 2) - (typeOrder[b.type] || 2);\n    });\n\n    // Limit to max skills\n    return activated.slice(0, CONFIG.maxSkills);\n}\n\n// Generate activation context message\nfunction generateContext(skills) {\n    if (skills.length === 0) {\n        return null;\n    }\n\n    const lines = [\n        '',\n        '━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━',\n        '🎯 SKILL ACTIVATION CHECK',\n        '━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━',\n        '',\n        'Relevant skills for this prompt:',\n        ''\n    ];\n\n    for (const skill of skills) {\n        const emoji = skill.priority === 'critical' ? '🔴' : \n                     skill.priority === 'high' ? '⭐' : \n                     skill.priority === 'medium' ? '📌' : '💡';\n        lines.push(\\`\\${emoji} **\\${skill.skill}** (\\${skill.priority} priority, \\${skill.type})\\`);\n\n        if (CONFIG.debugMode) {\n            lines.push(\\`   Matched: \\${skill.reason}\\`);\n        }\n    }\n\n    lines.push('');\n    lines.push('Before responding, check if any of these skills should be used.');\n    lines.push('Use the Skill tool to activate: \\`Skill command=\"hyperpowers:\u003cskill-name\u003e\"\\`');\n    lines.push('━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━');\n    lines.push('');\n\n    return lines.join('\\\\n');\n}\n\n// Main execution\nasync function main() {\n    try {\n        // Load rules\n        const rules = loadRules();\n\n        if (Object.keys(rules).length === 0) {\n            if (CONFIG.debugMode) {\n                console.error('No rules loaded');\n            }\n            console.log(JSON.stringify({ decision: 'continue' }));\n            return;\n        }\n\n        // Read prompt\n        const prompt = await readPrompt();\n\n        if (!prompt.text || prompt.text.trim() === '') {\n            console.log(JSON.stringify({ decision: 'continue' }));\n            return;\n        }\n\n        // Analyze prompt\n        const activatedSkills = analyzePrompt(prompt.text, rules);\n\n        // Generate response\n        if (activatedSkills.length \u003e 0) {\n            const context = generateContext(activatedSkills);\n\n            if (CONFIG.debugMode) {\n                console.error('Activated skills:', activatedSkills.map(s =\u003e s.skill).join(', '));\n            }\n\n            console.log(JSON.stringify({\n                decision: 'continue',\n                additionalContext: context\n            }));\n        } else {\n            if (CONFIG.debugMode) {\n                console.error('No skills activated');\n            }\n            console.log(JSON.stringify({ decision: 'continue' }));\n        }\n    } catch (error) {\n        if (CONFIG.debugMode) {\n            console.error('Hook error:', error.message, error.stack);\n        }\n        // Always continue on error - never block user\n        console.log(JSON.stringify({ decision: 'continue' }));\n    }\n}\n\nmain();\n\\`\\`\\`\n\n**Step 3: Make the script executable**\n\nRun:\n\\`\\`\\`bash\nchmod +x hooks/user-prompt-submit/10-skill-activator.js\n\\`\\`\\`\n\n### Step Group 2: Configure Hook in hooks.json\n\n**Files:**\n- Modify: hooks/hooks.json\n\n**Step 4: Read current hooks.json**\n\nRun:\n\\`\\`\\`bash\ncat hooks/hooks.json\n\\`\\`\\`\n\nExpected output shows current hooks (SessionStart, PreToolUse)\n\n**Step 5: Add UserPromptSubmit configuration**\n\nRead the current hooks.json, then update it to add the UserPromptSubmit hook. The complete hooks.json should look like:\n\n\\`\\`\\`json\n{\n  \"hooks\": {\n    \"SessionStart\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"\\${CLAUDE_PLUGIN_ROOT}/hooks/session-start.sh\"\n          }\n        ]\n      }\n    ],\n    \"PreToolUse\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"\\${CLAUDE_PLUGIN_ROOT}/hooks/block-beads-direct-read.py\"\n          }\n        ]\n      }\n    ],\n    \"UserPromptSubmit\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"\\${CLAUDE_PLUGIN_ROOT}/hooks/user-prompt-submit/10-skill-activator.js\"\n          }\n        ]\n      }\n    ]\n  }\n}\n\\`\\`\\`\n\n**Step 6: Validate hooks.json syntax**\n\nRun:\n\\`\\`\\`bash\njq . hooks/hooks.json \u003e /dev/null \u0026\u0026 echo \"✓ Valid JSON\" || echo \"✗ Invalid JSON\"\n\\`\\`\\`\n\nExpected: \"✓ Valid JSON\"\n\n### Step Group 3: Manual Testing\n\n**Files:**\n- Test: hooks/user-prompt-submit/10-skill-activator.js\n\n**Step 7: Create test script**\n\nCreate \\`hooks/user-prompt-submit/test-hook.sh\\`:\n\n\\`\\`\\`bash\n#!/bin/bash\nset -e\n\necho \"=== Testing Skill Activator Hook ===\"\necho \"\"\n\ntest_prompt() {\n    local prompt=\"\\$1\"\n    local expected_skills=\"\\$2\"\n    \n    echo \"Test: \\$prompt\"\n    result=\\$(echo \"{\\\\\"text\\\\\": \\\\\"\\$prompt\\\\\"}\" | node hooks/user-prompt-submit/10-skill-activator.js)\n    \n    if echo \"\\$result\" | jq -e '.decision == \"continue\"' \u003e /dev/null; then\n        echo \"✓ Returns continue decision\"\n    else\n        echo \"✗ FAIL: Wrong decision\"\n        return 1\n    fi\n    \n    if echo \"\\$result\" | jq -e '.additionalContext' \u003e /dev/null 2\u003e\u00261; then\n        activated=\\$(echo \"\\$result\" | jq -r '.additionalContext' | grep -oP '\\\\*\\\\*\\\\K[^*]+' || true)\n        echo \"  Activated: \\$activated\"\n        \n        if [ -n \"\\$expected_skills\" ]; then\n            for skill in \\$expected_skills; do\n                if echo \"\\$activated\" | grep -q \"\\$skill\"; then\n                    echo \"  ✓ Expected skill activated: \\$skill\"\n                else\n                    echo \"  ✗ Missing expected skill: \\$skill\"\n                fi\n            done\n        fi\n    else\n        echo \"  No skills activated\"\n    fi\n    \n    echo \"\"\n}\n\n# Test 1: TDD prompt should activate test-driven-development\ntest_prompt \"I want to write a test for the login function\" \"test-driven-development\"\n\n# Test 2: Debugging prompt should activate debugging-with-tools\ntest_prompt \"Help me debug this error in my code\" \"debugging-with-tools\"\n\n# Test 3: Planning prompt should activate brainstorming\ntest_prompt \"I want to design a new authentication system\" \"brainstorming\"\n\n# Test 4: Refactoring prompt should activate refactoring-safely\ntest_prompt \"Let's refactor this code to be cleaner\" \"refactoring-safely\"\n\n# Test 5: Empty prompt should return continue with no context\ntest_prompt \"\" \"\"\n\necho \"=== All Tests Complete ===\"\n\\`\\`\\`\n\n**Step 8: Make test script executable and run**\n\nRun:\n\\`\\`\\`bash\nchmod +x hooks/user-prompt-submit/test-hook.sh\nbash hooks/user-prompt-submit/test-hook.sh\n\\`\\`\\`\n\nExpected: All tests pass with appropriate skills activated\n\n**Step 9: Test performance**\n\nRun:\n\\`\\`\\`bash\ntime echo '{\"text\": \"I want to implement a new feature with TDD\"}' | node hooks/user-prompt-submit/10-skill-activator.js\n\\`\\`\\`\n\nExpected: Completes in \u003c100ms\n\n**Step 10: Test error handling**\n\nRun:\n\\`\\`\\`bash\n# Test with malformed JSON\necho 'invalid json' | node hooks/user-prompt-submit/10-skill-activator.js\n\\`\\`\\`\n\nExpected: Returns \\`{\"decision\":\"continue\"}\\` without crashing\n\n### Step Group 4: Integration Testing\n\n**Files:**\n- All created files\n\n**Step 11: Test in Claude Code environment (manual)**\n\nThis requires testing in an actual Claude Code session to verify the hook activates:\n\n1. Open a new Claude Code session in this project\n2. Type prompt: \"I want to write a test for authentication\"\n3. Observe if skill activation check appears before Claude's response\n4. Verify test-driven-development skill is suggested\n\n**Step 12: Debug if needed**\n\nIf hook doesn't activate, enable debug mode:\n\nRun:\n\\`\\`\\`bash\nexport DEBUG_HOOKS=true\n\\`\\`\\`\n\nThen check Claude Code logs for error messages from the hook.\n\n### Step Group 5: Commit Implementation\n\n**Step 13: Commit all files**\n\nRun:\n\\`\\`\\`bash\ngit add hooks/user-prompt-submit/10-skill-activator.js \\\\\n        hooks/user-prompt-submit/test-hook.sh \\\\\n        hooks/hooks.json\ngit commit -m \"\\$(cat \u003c\u003c'EOF'\nfeat(bd-4): implement UserPromptSubmit hook for skill activation\n\nImplements bd-4: UserPromptSubmit Hook (Skill Activator)\n- Created hooks/user-prompt-submit/10-skill-activator.js (Node.js hook)\n- Analyzes prompts using skill-rules.json patterns\n- Returns top 3 matching skills sorted by priority\n- Injects skill activation check as additionalContext\n- Handles errors gracefully (always returns decision: continue)\n- Performance: \u003c100ms for typical prompts\n- Manual testing script included\n- Updated hooks.json with UserPromptSubmit configuration\n\nThe hook parses user prompts, matches against keyword and intent patterns\nfrom skill-rules.json, and injects a skill activation reminder showing\nthe top 3 relevant skills before Claude processes the prompt.\n\n🤖 Generated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e\nEOF\n)\"\n\\`\\`\\`\n\nExpected: Commit successful\n\n**Step 14: Verify commit**\n\nRun:\n\\`\\`\\`bash\ngit log -1 --stat\n\\`\\`\\`\n\nExpected: Shows commit with 3 files changed\n\n## Key Considerations\n- **Error Handling**: Hook must ALWAYS return \\`{\"decision\": \"continue\"}\\` even on error - never block user\n- **Performance**: Keep analysis \u003c100ms - limit to top 3 skills to avoid context overload\n- **Priority Sorting**: critical \u003e high \u003e medium \u003e low, then process \u003e domain \u003e workflow\n- **Debug Mode**: Use DEBUG_HOOKS=true environment variable for troubleshooting\n- **Pattern Safety**: All regex patterns in skill-rules.json use lazy quantifiers to avoid catastrophic backtracking\n- **Graceful Degradation**: If skill-rules.json missing or malformed, return continue with no context\n- **JSON Output**: Must output valid JSON to stdout - errors go to stderr\n\n## Anti-patterns to Avoid\n- ❌ Blocking user if hook fails (always return decision: continue)\n- ❌ Loading skill-rules.json on every pattern check (load once at start)\n- ❌ Activating too many skills (limit to 3 to avoid context pollution)\n- ❌ Forgetting to make script executable (chmod +x)\n- ❌ Hardcoding paths instead of using __dirname and path.join\n- ❌ Not handling malformed JSON input gracefully\n- ❌ Using synchronous file operations in hot path (acceptable here since once per prompt)\n- ❌ Assuming Node.js modules available (only use built-in: fs, path)","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-30T13:57:03.288291-04:00","updated_at":"2025-10-30T15:33:42.356753-04:00","closed_at":"2025-10-30T15:33:42.356753-04:00","dependencies":[{"issue_id":"bd-4","depends_on_id":"bd-1","type":"parent-child","created_at":"2025-10-30T13:57:10.484473-04:00","created_by":"ryan"},{"issue_id":"bd-4","depends_on_id":"bd-3","type":"blocks","created_at":"2025-10-30T13:57:16.831676-04:00","created_by":"ryan"}]}
{"id":"bd-5","title":"Phase 4: PostToolUse Hook (Context Tracker)","description":"","design":"## Goal\nImplement hook that tracks file edits and maintains context.\n\n## Effort Estimate\n8-10 hours\n\n## Success Criteria\n- [ ] PostToolUse hook created and configured in hooks.json\n- [ ] Hook tracks Edit and Write tool usage\n- [ ] Context logged with: timestamp, repo, file_path, tool_name\n- [ ] Log stored in hooks/context/edit-log.txt\n- [ ] Log rotation prevents unbounded growth (max 1000 lines)\n- [ ] Non-blocking operation (always returns success)\n- [ ] Hook handles missing/malformed input gracefully\n- [ ] Manual testing shows correct logging of file edits\n- [ ] Context accessible to downstream hooks (bd-6)\n- [ ] Race condition prevention via file locking\n\n## Implementation Steps (ADDED BY writing-plans, REFINED BY SRE)\n\n### Step Group 1: Create Context Storage Infrastructure\n\n**Files:**\n- Create: hooks/context/ (directory)\n- Create: hooks/post-tool-use/01-track-edits.sh\n- Modify: hooks/hooks.json\n\n**Step 1: Create directories**\nRun:\n\\`\\`\\`bash\nmkdir -p hooks/post-tool-use hooks/context\n\\`\\`\\`\n\n**Step 2: Create the edit tracker script**\n\nCreate \\`hooks/post-tool-use/01-track-edits.sh\\`:\n\n\\`\\`\\`bash\n#!/usr/bin/env bash\nset -euo pipefail\n\n# Configuration\nCONTEXT_DIR=\"$(dirname \"$0\")/../context\"\nLOG_FILE=\"$CONTEXT_DIR/edit-log.txt\"\nLOCK_FILE=\"$CONTEXT_DIR/.edit-log.lock\"\nMAX_LOG_LINES=1000\nLOCK_TIMEOUT=5\n\n# Create context dir and log if doesn't exist\nmkdir -p \"$CONTEXT_DIR\"\ntouch \"$LOG_FILE\"\n\n# Acquire lock with timeout\nacquire_lock() {\n    local count=0\n    while [ $count -lt $LOCK_TIMEOUT ]; do\n        if mkdir \"$LOCK_FILE\" 2\u003e/dev/null; then\n            return 0\n        fi\n        sleep 0.2\n        count=$((count + 1))\n    done\n    # Log but don't fail - non-blocking requirement\n    echo \"Warning: Could not acquire lock\" \u003e\u00262\n    return 1\n}\n\n# Release lock\nrelease_lock() {\n    rmdir \"$LOCK_FILE\" 2\u003e/dev/null || true\n}\n\n# Clean up lock on exit\ntrap release_lock EXIT\n\n# Function to log edit\nlog_edit() {\n    local file_path=\"$1\"\n    local tool_name=\"$2\"\n    local timestamp=$(date +\"%Y-%m-%d %H:%M:%S\")\n    local repo=$(find_repo \"$file_path\")\n\n    if acquire_lock; then\n        echo \"$timestamp | $repo | $tool_name | $file_path\" \u003e\u003e \"$LOG_FILE\"\n        release_lock\n    fi\n}\n\n# Function to find repo root\nfind_repo() {\n    local file_path=\"$1\"\n    if [ -z \"$file_path\" ] || [ \"$file_path\" = \"null\" ]; then\n        echo \"unknown\"\n        return\n    fi\n\n    local dir\n    dir=$(dirname \"$file_path\" 2\u003e/dev/null || echo \"/\")\n    while [ \"$dir\" != \"/\" ] \u0026\u0026 [ -n \"$dir\" ]; do\n        if [ -d \"$dir/.git\" ]; then\n            basename \"$dir\"\n            return\n        fi\n        dir=$(dirname \"$dir\" 2\u003e/dev/null || echo \"/\")\n    done\n    echo \"unknown\"\n}\n\n# Read tool use event from stdin (with timeout to prevent hanging)\nif ! read -t 2 -r tool_use_json; then\n    echo '{\"decision\": \"continue\"}'\n    exit 0\nfi\n\n# Validate JSON to prevent injection\nif ! echo \"$tool_use_json\" | jq empty 2\u003e/dev/null; then\n    echo '{\"decision\": \"continue\"}'\n    exit 0\nfi\n\n# Extract tool name and file path from tool use\ntool_name=$(echo \"$tool_use_json\" | jq -r '.tool.name // .tool_name // \"unknown\"' 2\u003e/dev/null || echo \"unknown\")\nfile_path=\"\"\n\ncase \"$tool_name\" in\n    \"Edit\"|\"Write\")\n        file_path=$(echo \"$tool_use_json\" | jq -r '.tool.input.file_path // .tool_input.file_path // \"null\"' 2\u003e/dev/null || echo \"null\")\n        ;;\n    \"MultiEdit\")\n        # MultiEdit has multiple files - log each\n        echo \"$tool_use_json\" | jq -r '.tool.input.edits[]?.file_path // .tool_input.edits[]?.file_path // empty' 2\u003e/dev/null | while read -r path; do\n            if [ -n \"$path\" ] \u0026\u0026 [ \"$path\" != \"null\" ]; then\n                log_edit \"$path\" \"$tool_name\"\n            fi\n        done\n        echo '{\"decision\": \"continue\"}'\n        exit 0\n        ;;\nesac\n\n# Log single edit\nif [ -n \"$file_path\" ] \u0026\u0026 [ \"$file_path\" != \"null\" ]; then\n    log_edit \"$file_path\" \"$tool_name\"\nfi\n\n# Rotate log if too large (with lock)\nif acquire_lock; then\n    line_count=$(wc -l \u003c \"$LOG_FILE\" 2\u003e/dev/null || echo \"0\")\n    if [ \"$line_count\" -gt \"$MAX_LOG_LINES\" ]; then\n        tail -n \"$MAX_LOG_LINES\" \"$LOG_FILE\" \u003e \"$LOG_FILE.tmp\"\n        mv \"$LOG_FILE.tmp\" \"$LOG_FILE\"\n    fi\n    release_lock\nfi\n\n# Return success (non-blocking)\necho '{\"decision\": \"continue\"}'\n\\`\\`\\`\n\n**Step 3: Make script executable**\nRun:\n\\`\\`\\`bash\nchmod +x hooks/post-tool-use/01-track-edits.sh\n\\`\\`\\`\n\n### Step Group 2: Create Context Query Utilities\n\n**Step 4: Create context query utilities**\n\nCreate \\`hooks/utils/context-query.sh\\`:\n\n\\`\\`\\`bash\n#!/usr/bin/env bash\nset -euo pipefail\n\nCONTEXT_DIR=\"$(dirname \"$0\")/../context\"\nLOG_FILE=\"$CONTEXT_DIR/edit-log.txt\"\n\n# Get files edited since timestamp\nget_recent_edits() {\n    local since=\"${1:-}\"\n    \n    if [ ! -f \"$LOG_FILE\" ]; then\n        return 0\n    fi\n    \n    if [ -z \"$since\" ]; then\n        cat \"$LOG_FILE\" 2\u003e/dev/null || true\n    else\n        awk -v since=\"$since\" -F '|' '$1 \u003e= since' \"$LOG_FILE\" 2\u003e/dev/null || true\n    fi\n}\n\n# Get unique files edited in current session\nget_session_files() {\n    local session_start=\"${1:-}\"\n    \n    get_recent_edits \"$session_start\" | \\\\\n        awk -F '|' '{gsub(/^[ \\\\t]+|[ \\\\t]+$/, \"\", $4); print $4}' | \\\\\n        sort -u\n}\n\n# Check if specific file was edited\nwas_file_edited() {\n    local file_path=\"$1\"\n    local since=\"${2:-}\"\n    \n    get_recent_edits \"$since\" | grep -q \"$(printf '%q' \"$file_path\")\" 2\u003e/dev/null\n}\n\n# Get edit count by repo\nget_repo_stats() {\n    local since=\"${1:-}\"\n    \n    get_recent_edits \"$since\" | \\\\\n        awk -F '|' '{gsub(/^[ \\\\t]+|[ \\\\t]+$/, \"\", $2); print $2}' | \\\\\n        sort | uniq -c | sort -rn\n}\n\n# Clear log (for testing)\nclear_log() {\n    if [ -f \"$LOG_FILE\" ]; then\n        \u003e \"$LOG_FILE\"\n    fi\n}\n\\`\\`\\`\n\n## Key Considerations (ADDED BY SRE REVIEW)\n\n**Race Condition Prevention**:\n- Multiple hooks may run concurrently\n- Use directory-based locking (atomic on most filesystems)\n- Timeout on lock acquisition to prevent deadlock\n- Non-blocking requirement means we log warning but continue\n\n**Input Validation**:\n- Malformed JSON could cause jq to hang or error\n- Use jq empty to validate JSON structure first\n- Read with timeout to prevent hanging on stdin\n\n**Path Security**:\n- File paths may contain spaces, quotes, or shell metacharacters\n- Use proper quoting in all path operations\n- Validate paths don't contain directory traversal (..)\n\n**Disk Full Scenarios**:\n- All writes use \u003e\u003e which will fail gracefully if disk full\n- Log rotation prevents unbounded growth\n- Non-blocking means we continue even if write fails\n\n## Anti-patterns\n- ❌ Blocking on I/O or lock acquisition\n- ❌ Unbounded log growth without rotation\n- ❌ Crashing on malformed input\n- ❌ Not handling concurrent access\n- ❌ Shell injection via unquoted paths\n- ❌ Hanging on stdin read","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-30T13:57:03.298717-04:00","updated_at":"2025-10-30T15:36:27.582323-04:00","closed_at":"2025-10-30T15:36:27.582323-04:00","dependencies":[{"issue_id":"bd-5","depends_on_id":"bd-1","type":"parent-child","created_at":"2025-10-30T13:57:10.497915-04:00","created_by":"ryan"},{"issue_id":"bd-5","depends_on_id":"bd-4","type":"blocks","created_at":"2025-10-30T13:57:16.843566-04:00","created_by":"ryan"}]}
{"id":"bd-6","title":"Phase 5: Stop Hook (Gentle Reminders)","description":"","design":"## Goal\nImplement hook that shows self-check reminders after Claude responds.\n\n## Effort Estimate\n4-6 hours\n\n## Success Criteria\n- [ ] Stop hook created and configured in hooks.json\n- [ ] Reads context from edit-log.txt successfully\n- [ ] Shows TDD reminder if .ts/.js/.py files edited without test files\n- [ ] Shows verification reminder if user says \"done\" or \"complete\"\n- [ ] Shows commit reminder if \u003e3 files edited in session\n- [ ] Non-intrusive output (max 5 lines)\n- [ ] Handles missing/empty context gracefully\n- [ ] Performance \u003c50ms\n\n## Implementation Steps (ADDED BY writing-plans, REFINED BY SRE)\n\n### Step 1: Create Stop hook directory\nRun:\n\\`\\`\\`bash\nmkdir -p hooks/stop\n\\`\\`\\`\n\n### Step 2: Create gentle reminders hook\n\nCreate \\`hooks/stop/10-gentle-reminders.sh\\`:\n\n\\`\\`\\`bash\n#!/usr/bin/env bash\nset -euo pipefail\n\n# Configuration\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" \u0026\u0026 pwd)\"\nCONTEXT_DIR=\"$SCRIPT_DIR/../context\"\nUTILS_DIR=\"$SCRIPT_DIR/../utils\"\nLOG_FILE=\"$CONTEXT_DIR/edit-log.txt\"\nSESSION_START=$(date -d \"1 hour ago\" +\"%Y-%m-%d %H:%M:%S\" 2\u003e/dev/null || date -v-1H +\"%Y-%m-%d %H:%M:%S\")\n\n# Source utilities (if they exist)\nif [ -f \"$UTILS_DIR/context-query.sh\" ]; then\n    source \"$UTILS_DIR/context-query.sh\"\nelse\n    # Fallback if utilities missing\n    get_session_files() {\n        if [ -f \"$LOG_FILE\" ]; then\n            awk -F '|' -v since=\"$SESSION_START\" '$1 \u003e= since {gsub(/^[ \\\\t]+|[ \\\\t]+$/, \"\", $4); print $4}' \"$LOG_FILE\" | sort -u\n        fi\n    }\nfi\n\n# Read response from stdin to check for completion claims\nRESPONSE=\"\"\nif read -t 1 -r response_json 2\u003e/dev/null; then\n    RESPONSE=$(echo \"$response_json\" | jq -r '.text // \"\"' 2\u003e/dev/null || echo \"\")\nfi\n\n# Get edited files in this session\nEDITED_FILES=$(get_session_files \"$SESSION_START\" 2\u003e/dev/null || echo \"\")\nFILE_COUNT=$(echo \"$EDITED_FILES\" | grep -c . 2\u003e/dev/null || echo \"0\")\n\n# Check patterns for appropriate reminders\nSHOW_TDD_REMINDER=false\nSHOW_VERIFY_REMINDER=false\nSHOW_COMMIT_REMINDER=false\n\n# Check 1: Files edited but no test files?\nif [ \"$FILE_COUNT\" -gt 0 ]; then\n    # Check if source files edited\n    if echo \"$EDITED_FILES\" | grep -qE '\\\\.(ts|js|py|go|rs|java)$' 2\u003e/dev/null; then\n        # Check if NO test files edited\n        if ! echo \"$EDITED_FILES\" | grep -qE '(test|spec)\\\\.(ts|js|py|go|rs|java)$' 2\u003e/dev/null; then\n            SHOW_TDD_REMINDER=true\n        fi\n    fi\n    \n    # Check 2: Many files edited?\n    if [ \"$FILE_COUNT\" -ge 3 ]; then\n        SHOW_COMMIT_REMINDER=true\n    fi\nfi\n\n# Check 3: User claiming completion?\nif echo \"$RESPONSE\" | grep -iE '(done|complete|finished|ready|works)' \u003e/dev/null 2\u003e\u00261; then\n    SHOW_VERIFY_REMINDER=true\nfi\n\n# Display appropriate reminders (max 5 lines)\nif [ \"$SHOW_TDD_REMINDER\" = true ] || [ \"$SHOW_VERIFY_REMINDER\" = true ] || [ \"$SHOW_COMMIT_REMINDER\" = true ]; then\n    echo \"\"\n    echo \"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\"\n    \n    if [ \"$SHOW_TDD_REMINDER\" = true ]; then\n        echo \"💭 Remember: Write tests first (TDD)\"\n    fi\n    \n    if [ \"$SHOW_VERIFY_REMINDER\" = true ]; then\n        echo \"✅ Before claiming complete: Run tests\"\n    fi\n    \n    if [ \"$SHOW_COMMIT_REMINDER\" = true ]; then\n        echo \"💾 Consider: $FILE_COUNT files edited - commit?\"\n    fi\n    \n    echo \"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\"\nfi\n\n# Always return success (non-blocking)\nexit 0\n\\`\\`\\`\n\n### Step 3: Make executable\nRun:\n\\`\\`\\`bash\nchmod +x hooks/stop/10-gentle-reminders.sh\n\\`\\`\\`\n\n### Step 4: Update hooks.json\n\nAdd Stop hook configuration to \\`hooks/hooks.json\\` (preserve existing entries):\n\n\\`\\`\\`json\n{\n  \"hooks\": {\n    \"SessionStart\": [...],\n    \"PreToolUse\": [...],\n    \"UserPromptSubmit\": [...],\n    \"PostToolUse\": [...],\n    \"Stop\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"${CLAUDE_PLUGIN_ROOT}/hooks/stop/10-gentle-reminders.sh\"\n          }\n        ]\n      }\n    ]\n  }\n}\n\\`\\`\\`\n\n### Step 5: Create test script\n\nCreate \\`hooks/stop/test-reminders.sh\\`:\n\n\\`\\`\\`bash\n#!/bin/bash\nset -e\n\necho \"=== Testing Stop Hook Reminders ===\"\n\n# Test 1: No edits = no reminder\necho \"Test 1: No edits\"\n\u003e hooks/context/edit-log.txt\necho '{\"text\": \"All done!\"}' | bash hooks/stop/10-gentle-reminders.sh \u003e /tmp/out1.txt\n[ ! -s /tmp/out1.txt ] \u0026\u0026 echo \"✓ No reminder (correct)\" || echo \"✗ Unexpected reminder\"\n\n# Test 2: Source file edited without test = TDD reminder\necho \"Test 2: TDD reminder\"\necho \"$(date +\"%Y-%m-%d %H:%M:%S\") | hyper | Edit | src/main.ts\" \u003e hooks/context/edit-log.txt\necho '{\"text\": \"Feature implemented\"}' | bash hooks/stop/10-gentle-reminders.sh \u003e /tmp/out2.txt\ngrep -q \"TDD\" /tmp/out2.txt \u0026\u0026 echo \"✓ TDD reminder shown\" || echo \"✗ TDD reminder missing\"\n\n# Test 3: Completion claim = verification reminder\necho \"Test 3: Verification reminder\"\necho '{\"text\": \"All done and tests pass!\"}' | bash hooks/stop/10-gentle-reminders.sh \u003e /tmp/out3.txt\ngrep -q \"Run tests\" /tmp/out3.txt \u0026\u0026 echo \"✓ Verify reminder shown\" || echo \"✗ Verify reminder missing\"\n\n# Test 4: Many files = commit reminder\necho \"Test 4: Commit reminder\"\nfor i in {1..5}; do\n    echo \"$(date +\"%Y-%m-%d %H:%M:%S\") | hyper | Edit | src/file$i.ts\" \u003e\u003e hooks/context/edit-log.txt\ndone\necho '{\"text\": \"Refactoring complete\"}' | bash hooks/stop/10-gentle-reminders.sh \u003e /tmp/out4.txt\ngrep -q \"commit\" /tmp/out4.txt \u0026\u0026 echo \"✓ Commit reminder shown\" || echo \"✗ Commit reminder missing\"\n\necho \"=== All Tests Complete ===\"\n\\`\\`\\`\n\n### Step 6: Run tests\nRun:\n\\`\\`\\`bash\nchmod +x hooks/stop/test-reminders.sh\nbash hooks/stop/test-reminders.sh\n\\`\\`\\`\n\nExpected: All tests pass\n\n### Step 7: Test performance\nRun:\n\\`\\`\\`bash\ntime echo '{\"text\": \"Done\"}' | bash hooks/stop/10-gentle-reminders.sh\n\\`\\`\\`\n\nExpected: \u003c50ms execution time\n\n### Step 8: Commit\nRun:\n\\`\\`\\`bash\ngit add hooks/stop/10-gentle-reminders.sh hooks/stop/test-reminders.sh hooks/hooks.json\ngit commit -m \"feat(bd-6): implement Stop hook for gentle reminders\n\nImplements bd-6: Stop Hook (Gentle Reminders)\n- Shows TDD reminder when source edited without tests\n- Shows verification reminder when user claims complete\n- Shows commit reminder when many files edited\n- Non-intrusive (max 5 lines output)\n- Performance \u003c50ms\"\n\\`\\`\\`\n\n## Key Considerations (ADDED BY SRE REVIEW)\n\n**Context Availability**:\n- edit-log.txt may not exist (fresh install)\n- PostToolUse hook (bd-5) may not be running\n- Must handle gracefully with fallbacks\n\n**Pattern Matching Accuracy**:\n- Avoid false positives (e.g., \"done\" in middle of sentence)\n- Source vs test file detection must be accurate\n- Consider different naming conventions (test.js, spec.js, _test.go)\n\n**User Experience**:\n- Keep output brief (max 5 lines)\n- Only show relevant reminders, not all\n- Use clear, actionable language\n\n**Performance**:\n- Stop hook runs after every Claude response\n- Must be fast (\u003c50ms) to not delay user\n- Avoid complex processing or external commands\n\n## Anti-patterns\n- ❌ Annoying/repetitive reminders every response\n- ❌ Blocking on I/O or missing files\n- ❌ Long multi-paragraph reminders\n- ❌ False positive pattern matching\n- ❌ Slow execution delaying response","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-30T13:57:03.309595-04:00","updated_at":"2025-10-30T15:38:52.605286-04:00","closed_at":"2025-10-30T15:38:52.605286-04:00","dependencies":[{"issue_id":"bd-6","depends_on_id":"bd-1","type":"parent-child","created_at":"2025-10-30T13:57:10.518056-04:00","created_by":"ryan"},{"issue_id":"bd-6","depends_on_id":"bd-5","type":"blocks","created_at":"2025-10-30T13:57:16.854063-04:00","created_by":"ryan"}]}
{"id":"bd-7","title":"Phase 6: Update Documentation","description":"","design":"## Goal  \nUpdate documentation for new hooks system.\n\n## Effort Estimate\n2-4 hours\n\n## Success Criteria\n- [ ] README.md updated with Hooks System section\n- [ ] Each hook type documented with examples\n- [ ] Installation instructions include hook setup\n- [ ] Troubleshooting section added\n- [ ] skills/skills-auto-activation/SKILL.md references updated\n- [ ] All code examples tested and working\n\n## Implementation Steps (ADDED BY writing-plans, REFINED BY SRE)\n\n### Step 1: Update main README.md\n\nAdd the following section after \"## Features\" in README.md:\n\n\\`\\`\\`markdown\n## Hooks System\n\nHyperpowers includes an intelligent hooks system that provides context-aware assistance:\n\n### Automatic Skill Activation\nWhen you type a prompt, the UserPromptSubmit hook analyzes it and suggests relevant skills:\n\n\\`\\`\\`\nUser: I want to write a test for the login function\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n🎯 SKILL ACTIVATION CHECK\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n⭐ **test-driven-development** (high priority, process)\n📌 **debugging-with-tools** (medium priority, process)\n\nUse the Skill tool to activate: \\`Skill command=\"hyperpowers:test-driven-development\"\\`\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\\`\\`\\`\n\n### Context Tracking\nThe PostToolUse hook tracks file edits during your session, maintaining context for intelligent reminders.\n\n### Gentle Reminders\nAfter Claude responds, the Stop hook provides helpful reminders based on context:\n- 💭 TDD reminder when editing source without tests\n- ✅ Verification reminder when claiming completion\n- 💾 Commit reminder after multiple file edits\n\n### Hook Configuration\n\nHooks are configured in \\`hooks/hooks.json\\`:\n\n\\`\\`\\`json\n{\n  \"hooks\": {\n    \"UserPromptSubmit\": [...],  // Skill activation\n    \"PostToolUse\": [...],        // Context tracking\n    \"Stop\": [...]                // Gentle reminders\n  }\n}\n\\`\\`\\`\n\\`\\`\\`\n\n### Step 2: Create HOOKS.md documentation\n\nCreate \\`HOOKS.md\\` in project root:\n\n\\`\\`\\`markdown\n# Hyperpowers Hooks Documentation\n\n## Overview\nHyperpowers uses Claude Code's hooks system to provide intelligent, context-aware assistance.\n\n## Hook Types\n\n### UserPromptSubmit Hook\n**File:** \\`hooks/user-prompt-submit/10-skill-activator.js\\`\n**Purpose:** Analyzes prompts and suggests relevant skills\n**Input:** \\`{\"text\": \"user prompt text\"}\\`\n**Output:** \\`{\"decision\": \"continue\", \"additionalContext\": \"skill suggestions\"}\\`\n\n**Configuration:**\n- Edit \\`hooks/skill-rules.json\\` to adjust skill triggers\n- Set \\`DEBUG_HOOKS=true\\` for troubleshooting\n\n### PostToolUse Hook  \n**File:** \\`hooks/post-tool-use/01-track-edits.sh\\`\n**Purpose:** Tracks file edits for context\n**Input:** \\`{\"tool\": {\"name\": \"Edit\", \"input\": {\"file_path\": \"...\"}}}\\`\n**Output:** \\`{\"decision\": \"continue\"}\\`\n\n**Context Storage:**\n- Log file: \\`hooks/context/edit-log.txt\\`\n- Format: \\`timestamp | repo | tool | filepath\\`\n- Auto-rotates at 1000 lines\n\n### Stop Hook\n**File:** \\`hooks/stop/10-gentle-reminders.sh\\`\n**Purpose:** Shows context-aware reminders\n**Input:** \\`{\"text\": \"claude's response\"}\\` (optional)\n**Output:** Brief reminders to stdout\n\n## Installation\n\n1. Ensure Node.js is installed (for skill activator)\n2. Hooks auto-activate when plugin is loaded\n3. Verify with: \\`ls hooks/\\`\n\n## Troubleshooting\n\n### Skill activator not working\n\\`\\`\\`bash\n# Enable debug mode\nexport DEBUG_HOOKS=true\n\n# Test manually\necho '{\"text\": \"I want to write a test\"}' | node hooks/user-prompt-submit/10-skill-activator.js\n\\`\\`\\`\n\n### Context not tracking\n\\`\\`\\`bash\n# Check log file\ncat hooks/context/edit-log.txt\n\n# Test manually\necho '{\"tool\": {\"name\": \"Edit\", \"input\": {\"file_path\": \"/test.ts\"}}}' | \\\\\n  bash hooks/post-tool-use/01-track-edits.sh\n\\`\\`\\`\n\n### Reminders not showing\n\\`\\`\\`bash\n# Test manually\necho '{\"text\": \"All done!\"}' | bash hooks/stop/10-gentle-reminders.sh\n\\`\\`\\`\n\n## Customization\n\n### Adjusting skill triggers\nEdit \\`hooks/skill-rules.json\\`:\n\\`\\`\\`json\n{\n  \"skill-name\": {\n    \"priority\": \"high\",\n    \"promptTriggers\": {\n      \"keywords\": [\"test\", \"testing\"],\n      \"intentPatterns\": [\"write.*test\", \"create.*spec\"]\n    }\n  }\n}\n\\`\\`\\`\n\n### Disabling hooks\nRemove from \\`hooks/hooks.json\\` or rename hook file.\n\n## Performance\n\n- UserPromptSubmit: \u003c100ms per prompt\n- PostToolUse: \u003c10ms per edit\n- Stop: \u003c50ms per response\n\\`\\`\\`\n\n### Step 3: Update skills/skills-auto-activation/SKILL.md\n\nAdd reference at the top of the file:\n\n\\`\\`\\`markdown\n---\nname: skills-auto-activation\ndescription: Automatically activated via hooks/user-prompt-submit/10-skill-activator.js\n---\n\n\u003e **Note:** This skill's functionality is now implemented via the hooks system.\n\u003e The UserPromptSubmit hook automatically suggests relevant skills based on your prompts.\n\u003e See HOOKS.md for configuration details.\n\\`\\`\\`\n\n### Step 4: Test documentation examples\n\nRun each code example from the documentation:\n\n\\`\\`\\`bash\n# Test skill activator example\necho '{\"text\": \"I want to write a test for the login function\"}' | \\\\\n  node hooks/user-prompt-submit/10-skill-activator.js | \\\\\n  jq .additionalContext\n\n# Test context tracker example  \necho '{\"tool\": {\"name\": \"Edit\", \"input\": {\"file_path\": \"/test.ts\"}}}' | \\\\\n  bash hooks/post-tool-use/01-track-edits.sh\n\n# Test reminder example\necho '{\"text\": \"All done!\"}' | bash hooks/stop/10-gentle-reminders.sh\n\\`\\`\\`\n\nExpected: All examples work as documented\n\n### Step 5: Commit documentation\n\nRun:\n\\`\\`\\`bash\ngit add README.md HOOKS.md skills/skills-auto-activation/SKILL.md\ngit commit -m \"docs(bd-7): add comprehensive hooks documentation\n\nImplements bd-7: Update Documentation\n- Added Hooks System section to README.md\n- Created detailed HOOKS.md with examples\n- Added troubleshooting guide\n- Updated skill references\n- All examples tested and working\"\n\\`\\`\\`\n\n## Key Considerations (ADDED BY SRE REVIEW)\n\n**Documentation Accuracy**:\n- All code examples MUST be tested\n- File paths must match actual implementation\n- Version requirements (Node.js) must be stated\n\n**User Experience**:\n- Start with benefits, not technical details\n- Provide clear examples before configuration\n- Troubleshooting should cover common issues\n\n**Maintenance**:\n- Documentation must be updated when hooks change\n- Include version/compatibility notes\n- Link to relevant skills and resources\n\n## Anti-patterns\n- ❌ Outdated code examples\n- ❌ Missing prerequisites (Node.js)\n- ❌ Complex explanations before simple examples\n- ❌ Documentation that contradicts implementation","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-30T13:57:03.320096-04:00","updated_at":"2025-10-30T15:41:24.506886-04:00","closed_at":"2025-10-30T15:41:24.506886-04:00","dependencies":[{"issue_id":"bd-7","depends_on_id":"bd-1","type":"parent-child","created_at":"2025-10-30T13:57:10.532603-04:00","created_by":"ryan"},{"issue_id":"bd-7","depends_on_id":"bd-6","type":"blocks","created_at":"2025-10-30T13:57:16.864384-04:00","created_by":"ryan"}]}
{"id":"bd-8","title":"Phase 7: Integration Testing","description":"","design":"## Goal\nTest complete hook system integration.\n\n## Effort Estimate  \n4-6 hours\n\n## Success Criteria\n- [ ] End-to-end test script created\n- [ ] All 3 hooks tested in sequence\n- [ ] 10+ test scenarios pass\n- [ ] Performance benchmarks documented\n- [ ] Error scenarios handled correctly\n- [ ] No interference between hooks\n- [ ] Clean test environment setup/teardown\n\n## Implementation Steps (ADDED BY writing-plans, REFINED BY SRE)\n\n### Step 1: Create integration test script\n\nCreate \\`hooks/test/integration-test.sh\\`:\n\n\\`\\`\\`bash\n#!/usr/bin/env bash\nset -euo pipefail\n\n# Colors for output\nRED='\\\\033[0;31m'\nGREEN='\\\\033[0;32m'\nYELLOW='\\\\033[1;33m'\nNC='\\\\033[0m' # No Color\n\n# Test environment setup\nTEST_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" \u0026\u0026 pwd)\"\nHOOKS_DIR=\"$(dirname \"$TEST_DIR\")\"\nCONTEXT_DIR=\"$HOOKS_DIR/context\"\nORIG_LOG=\"\"\n\n# Test counters\nTESTS_RUN=0\nTESTS_PASSED=0\nTESTS_FAILED=0\n\n# Utility functions\nsetup_test() {\n    echo -e \"${YELLOW}Setting up test environment...${NC}\"\n    # Backup existing log\n    if [ -f \"$CONTEXT_DIR/edit-log.txt\" ]; then\n        ORIG_LOG=$(cat \"$CONTEXT_DIR/edit-log.txt\")\n    fi\n    \u003e \"$CONTEXT_DIR/edit-log.txt\"\n    export DEBUG_HOOKS=false\n}\n\nteardown_test() {\n    echo -e \"${YELLOW}Cleaning up test environment...${NC}\"\n    # Restore original log\n    if [ -n \"$ORIG_LOG\" ]; then\n        echo \"$ORIG_LOG\" \u003e \"$CONTEXT_DIR/edit-log.txt\"\n    else\n        \u003e \"$CONTEXT_DIR/edit-log.txt\"\n    fi\n}\n\nrun_test() {\n    local test_name=\"$1\"\n    local test_cmd=\"$2\"\n    local expected=\"$3\"\n    \n    TESTS_RUN=$((TESTS_RUN + 1))\n    echo -n \"Test $TESTS_RUN: $test_name... \"\n    \n    if eval \"$test_cmd\" 2\u003e/dev/null | grep -q \"$expected\" 2\u003e/dev/null; then\n        echo -e \"${GREEN}PASS${NC}\"\n        TESTS_PASSED=$((TESTS_PASSED + 1))\n    else\n        echo -e \"${RED}FAIL${NC}\"\n        echo \"  Expected: $expected\"\n        echo \"  Command: $test_cmd\"\n        TESTS_FAILED=$((TESTS_FAILED + 1))\n    fi\n}\n\n# Performance test utility\nmeasure_performance() {\n    local hook_name=\"$1\"\n    local test_input=\"$2\"\n    local hook_script=\"$3\"\n    \n    local start=$(date +%s%N)\n    echo \"$test_input\" | $hook_script \u003e /dev/null 2\u003e\u00261\n    local end=$(date +%s%N)\n    \n    local duration_ms=$(((end - start) / 1000000))\n    echo \"$duration_ms\"\n}\n\n# Main test execution\nmain() {\n    echo \"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\"\n    echo \"🧪 HOOKS INTEGRATION TEST SUITE\"\n    echo \"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\"\n    echo \"\"\n    \n    setup_test\n    \n    # Test 1: UserPromptSubmit - Skill activation\n    echo -e \"\\\\n${YELLOW}Testing UserPromptSubmit Hook...${NC}\"\n    \n    run_test \"TDD prompt activates skill\" \\\\\n        \"echo '{\\\"text\\\": \\\"I want to write a test for login\\\"}' | node $HOOKS_DIR/user-prompt-submit/10-skill-activator.js\" \\\\\n        \"test-driven-development\"\n    \n    run_test \"Empty prompt returns continue\" \\\\\n        \"echo '{\\\"text\\\": \\\"\\\"}' | node $HOOKS_DIR/user-prompt-submit/10-skill-activator.js\" \\\\\n        '{\"decision\":\"continue\"}'\n    \n    run_test \"Malformed JSON handled\" \\\\\n        \"echo 'not json' | node $HOOKS_DIR/user-prompt-submit/10-skill-activator.js\" \\\\\n        '{\"decision\":\"continue\"}'\n    \n    # Test 2: PostToolUse - Context tracking\n    echo -e \"\\\\n${YELLOW}Testing PostToolUse Hook...${NC}\"\n    \n    run_test \"Edit tool logs file\" \\\\\n        \"echo '{\\\"tool\\\": {\\\"name\\\": \\\"Edit\\\", \\\"input\\\": {\\\"file_path\\\": \\\"/test/file1.ts\\\"}}}' | bash $HOOKS_DIR/post-tool-use/01-track-edits.sh \u0026\u0026 tail -1 $CONTEXT_DIR/edit-log.txt\" \\\\\n        \"file1.ts\"\n    \n    run_test \"Write tool logs file\" \\\\\n        \"echo '{\\\"tool\\\": {\\\"name\\\": \\\"Write\\\", \\\"input\\\": {\\\"file_path\\\": \\\"/test/file2.py\\\"}}}' | bash $HOOKS_DIR/post-tool-use/01-track-edits.sh \u0026\u0026 tail -1 $CONTEXT_DIR/edit-log.txt\" \\\\\n        \"file2.py\"\n    \n    run_test \"Invalid tool ignored\" \\\\\n        \"echo '{\\\"tool\\\": {\\\"name\\\": \\\"Read\\\", \\\"input\\\": {\\\"file_path\\\": \\\"/test/file3.ts\\\"}}}' | bash $HOOKS_DIR/post-tool-use/01-track-edits.sh\" \\\\\n        '{\"decision\":\"continue\"}'\n    \n    # Test 3: Stop - Gentle reminders\n    echo -e \"\\\\n${YELLOW}Testing Stop Hook...${NC}\"\n    \n    # Add source file edit for TDD reminder\n    echo \"$(date +\"%Y-%m-%d %H:%M:%S\") | test | Edit | /src/main.ts\" \u003e\u003e \"$CONTEXT_DIR/edit-log.txt\"\n    \n    run_test \"TDD reminder shows\" \\\\\n        \"echo '{\\\"text\\\": \\\"Feature implemented\\\"}' | bash $HOOKS_DIR/stop/10-gentle-reminders.sh\" \\\\\n        \"TDD\"\n    \n    run_test \"Completion triggers verify\" \\\\\n        \"echo '{\\\"text\\\": \\\"All done and working!\\\"}' | bash $HOOKS_DIR/stop/10-gentle-reminders.sh\" \\\\\n        \"Run tests\"\n    \n    # Add multiple files for commit reminder\n    for i in {1..5}; do\n        echo \"$(date +\"%Y-%m-%d %H:%M:%S\") | test | Edit | /src/file$i.ts\" \u003e\u003e \"$CONTEXT_DIR/edit-log.txt\"\n    done\n    \n    run_test \"Many edits triggers commit\" \\\\\n        \"echo '{\\\"text\\\": \\\"Refactoring\\\"}' | bash $HOOKS_DIR/stop/10-gentle-reminders.sh\" \\\\\n        \"commit\"\n    \n    # Test 4: End-to-end workflow\n    echo -e \"\\\\n${YELLOW}Testing End-to-End Workflow...${NC}\"\n    \n    # Clear log for clean test\n    \u003e \"$CONTEXT_DIR/edit-log.txt\"\n    \n    # Simulate full workflow\n    echo \"Step 1: User prompt with TDD intent\"\n    result1=$(echo '{\"text\": \"I need to implement authentication with tests\"}' | \\\\\n              node \"$HOOKS_DIR/user-prompt-submit/10-skill-activator.js\")\n    \n    if echo \"$result1\" | grep -q \"test-driven-development\"; then\n        echo -e \"  ${GREEN}✓ Skill activated${NC}\"\n    else\n        echo -e \"  ${RED}✗ Skill not activated${NC}\"\n        TESTS_FAILED=$((TESTS_FAILED + 1))\n    fi\n    \n    echo \"Step 2: Edit files (triggers context tracking)\"\n    echo '{\"tool\": {\"name\": \"Edit\", \"input\": {\"file_path\": \"/src/auth.ts\"}}}' | \\\\\n        bash \"$HOOKS_DIR/post-tool-use/01-track-edits.sh\" \u003e /dev/null\n    \n    if grep -q \"auth.ts\" \"$CONTEXT_DIR/edit-log.txt\"; then\n        echo -e \"  ${GREEN}✓ Edit tracked${NC}\"\n    else\n        echo -e \"  ${RED}✗ Edit not tracked${NC}\"\n        TESTS_FAILED=$((TESTS_FAILED + 1))\n    fi\n    \n    echo \"Step 3: Response triggers reminder\"\n    result3=$(echo '{\"text\": \"Authentication implemented successfully!\"}' | \\\\\n              bash \"$HOOKS_DIR/stop/10-gentle-reminders.sh\")\n    \n    if echo \"$result3\" | grep -q \"TDD\\\\|test\"; then\n        echo -e \"  ${GREEN}✓ Reminder shown${NC}\"\n    else\n        echo -e \"  ${RED}✗ No reminder${NC}\"\n        TESTS_FAILED=$((TESTS_FAILED + 1))\n    fi\n    \n    # Test 5: Performance benchmarks\n    echo -e \"\\\\n${YELLOW}Performance Benchmarks...${NC}\"\n    \n    perf1=$(measure_performance \"UserPromptSubmit\" \\\\\n            '{\"text\": \"I want to write tests\"}' \\\\\n            \"node $HOOKS_DIR/user-prompt-submit/10-skill-activator.js\")\n    \n    perf2=$(measure_performance \"PostToolUse\" \\\\\n            '{\"tool\": {\"name\": \"Edit\", \"input\": {\"file_path\": \"/test.ts\"}}}' \\\\\n            \"bash $HOOKS_DIR/post-tool-use/01-track-edits.sh\")\n    \n    perf3=$(measure_performance \"Stop\" \\\\\n            '{\"text\": \"Done\"}' \\\\\n            \"bash $HOOKS_DIR/stop/10-gentle-reminders.sh\")\n    \n    echo \"UserPromptSubmit: ${perf1}ms (target: \u003c100ms)\"\n    echo \"PostToolUse: ${perf2}ms (target: \u003c10ms)\"\n    echo \"Stop: ${perf3}ms (target: \u003c50ms)\"\n    \n    # Check performance targets\n    if [ \"$perf1\" -lt 100 ] \u0026\u0026 [ \"$perf2\" -lt 10 ] \u0026\u0026 [ \"$perf3\" -lt 50 ]; then\n        echo -e \"${GREEN}✓ All performance targets met${NC}\"\n        TESTS_PASSED=$((TESTS_PASSED + 1))\n    else\n        echo -e \"${RED}✗ Performance targets not met${NC}\"\n        TESTS_FAILED=$((TESTS_FAILED + 1))\n    fi\n    \n    teardown_test\n    \n    # Summary\n    echo \"\"\n    echo \"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\"\n    echo \"📊 TEST RESULTS\"\n    echo \"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\"\n    echo \"Total: $TESTS_RUN\"\n    echo -e \"Passed: ${GREEN}$TESTS_PASSED${NC}\"\n    echo -e \"Failed: ${RED}$TESTS_FAILED${NC}\"\n    \n    if [ \"$TESTS_FAILED\" -eq 0 ]; then\n        echo -e \"\\\\n${GREEN}✅ ALL TESTS PASSED!${NC}\"\n        exit 0\n    else\n        echo -e \"\\\\n${RED}❌ SOME TESTS FAILED${NC}\"\n        exit 1\n    fi\n}\n\n# Run tests\nmain\n\\`\\`\\`\n\n### Step 2: Make test executable and run\n\nRun:\n\\`\\`\\`bash\nchmod +x hooks/test/integration-test.sh\nbash hooks/test/integration-test.sh\n\\`\\`\\`\n\nExpected output:\n- All tests pass (green checkmarks)\n- Performance within targets\n- No errors or warnings\n\n### Step 3: Create error scenario tests\n\nCreate \\`hooks/test/error-test.sh\\`:\n\n\\`\\`\\`bash\n#!/bin/bash\nset -e\n\necho \"=== Testing Error Scenarios ===\"\n\n# Test 1: Missing skill-rules.json\necho \"Test 1: Missing skill-rules.json\"\nmv hooks/skill-rules.json hooks/skill-rules.json.bak 2\u003e/dev/null || true\nresult=$(echo '{\"text\": \"test\"}' | node hooks/user-prompt-submit/10-skill-activator.js 2\u003e/dev/null)\n[ \"$result\" = '{\"decision\":\"continue\"}' ] \u0026\u0026 echo \"✓ Handled gracefully\" || echo \"✗ Failed\"\nmv hooks/skill-rules.json.bak hooks/skill-rules.json 2\u003e/dev/null || true\n\n# Test 2: Corrupted edit-log.txt\necho \"Test 2: Corrupted log file\"\necho \"invalid|data|format\" \u003e hooks/context/edit-log.txt\nbash hooks/stop/10-gentle-reminders.sh \u003c/dev/null \u003e/dev/null 2\u003e\u00261 \u0026\u0026 echo \"✓ Handled gracefully\" || echo \"✗ Crashed\"\n\n# Test 3: Permission denied on log\necho \"Test 3: Permission denied\"\nchmod 000 hooks/context/edit-log.txt 2\u003e/dev/null || true\necho '{\"tool\": {\"name\": \"Edit\", \"input\": {\"file_path\": \"/test.ts\"}}}' | \\\\\n  bash hooks/post-tool-use/01-track-edits.sh \u003e/dev/null 2\u003e\u00261\n[ $? -eq 0 ] \u0026\u0026 echo \"✓ Continued despite error\" || echo \"✗ Failed\"\nchmod 644 hooks/context/edit-log.txt 2\u003e/dev/null || true\n\n# Test 4: Concurrent access\necho \"Test 4: Concurrent writes\"\nfor i in {1..10}; do\n    echo '{\"tool\": {\"name\": \"Edit\", \"input\": {\"file_path\": \"/test'$i'.ts\"}}}' | \\\\\n      bash hooks/post-tool-use/01-track-edits.sh \u0026\ndone\nwait\nlines=$(wc -l \u003c hooks/context/edit-log.txt)\n[ \"$lines\" -ge 8 ] \u0026\u0026 echo \"✓ Most writes succeeded\" || echo \"✗ Lost writes\"\n\necho \"=== Error Tests Complete ===\"\n\\`\\`\\`\n\n### Step 4: Run error tests\n\nRun:\n\\`\\`\\`bash\nchmod +x hooks/test/error-test.sh\nbash hooks/test/error-test.sh\n\\`\\`\\`\n\nExpected: All error scenarios handled gracefully\n\n### Step 5: Create performance stress test\n\nCreate \\`hooks/test/stress-test.sh\\`:\n\n\\`\\`\\`bash\n#!/bin/bash\necho \"=== Performance Stress Test ===\"\n\n# Test with very long prompt (10KB)\nlong_prompt=$(python3 -c \"print('test ' * 2000)\")\ntime echo \"{\\\"text\\\": \\\"$long_prompt\\\"}\" | node hooks/user-prompt-submit/10-skill-activator.js \u003e /dev/null\n\n# Test with 100 rapid edits\ntime for i in {1..100}; do\n    echo '{\"tool\": {\"name\": \"Edit\", \"input\": {\"file_path\": \"/test'$i'.ts\"}}}' | \\\\\n      bash hooks/post-tool-use/01-track-edits.sh\ndone\n\necho \"Stress test complete\"\n\\`\\`\\`\n\n### Step 6: Document test results\n\nCreate \\`hooks/test/TEST-RESULTS.md\\`:\n\n\\`\\`\\`markdown\n# Hook System Test Results\n\nDate: [Current Date]\nVersion: 1.0.0\n\n## Integration Tests\n- ✅ 10/10 scenarios pass\n- ✅ End-to-end workflow verified\n- ✅ Performance targets met\n\n## Error Handling\n- ✅ Missing files handled\n- ✅ Corrupted data handled\n- ✅ Permission errors handled\n- ✅ Concurrent access safe\n\n## Performance\n| Hook | Target | Actual | Status |\n|------|--------|--------|--------|\n| UserPromptSubmit | \u003c100ms | XXms | ✅ |\n| PostToolUse | \u003c10ms | XXms | ✅ |\n| Stop | \u003c50ms | XXms | ✅ |\n\n## Stress Test\n- 10KB prompt: XXXms\n- 100 rapid edits: XXXms total\n\\`\\`\\`\n\n### Step 7: Commit tests\n\nRun:\n\\`\\`\\`bash\ngit add hooks/test/*.sh hooks/test/TEST-RESULTS.md\ngit commit -m \"test(bd-8): comprehensive integration tests\n\nImplements bd-8: Integration Testing\n- End-to-end workflow tests\n- Error scenario handling\n- Performance benchmarks\n- Stress testing\n- All tests passing\"\n\\`\\`\\`\n\n## Key Considerations (ADDED BY SRE REVIEW)\n\n**Test Coverage**:\n- Happy path (normal operation)\n- Error cases (missing files, bad data)\n- Edge cases (empty input, huge input)\n- Concurrent access\n- Performance under load\n\n**Test Isolation**:\n- Save/restore original state\n- Clean environment for each test\n- No side effects between tests\n\n**Realistic Scenarios**:\n- Test actual user workflows\n- Include timing/performance checks\n- Verify hook interaction\n\n**Maintenance**:\n- Tests must be repeatable\n- Clear failure messages\n- Easy to add new test cases\n\n## Anti-patterns\n- ❌ Only testing happy path\n- ❌ Tests that depend on external state\n- ❌ No performance validation\n- ❌ Unclear failure messages\n- ❌ Tests that can't be run repeatedly","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-30T13:57:03.330003-04:00","updated_at":"2025-10-30T15:43:58.539522-04:00","closed_at":"2025-10-30T15:43:58.539522-04:00","dependencies":[{"issue_id":"bd-8","depends_on_id":"bd-1","type":"parent-child","created_at":"2025-10-30T13:57:10.547958-04:00","created_by":"ryan"},{"issue_id":"bd-8","depends_on_id":"bd-7","type":"blocks","created_at":"2025-10-30T13:57:16.875377-04:00","created_by":"ryan"}]}
{"id":"bd-9","title":"Bug: Hooks using invalid 'continue' decision instead of 'approve' or 'deny'","description":"","design":"## Root Cause Analysis\n\nThe hooks implementation used 'continue' as a decision value, which was incorrect. The fix changed it to 'approve', but that's ALSO incorrect!\n\nAccording to Claude Code official documentation:\n\n**Valid decision values by hook type:**\n- **PreToolUse**: 'allow', 'deny', 'ask'\n- **PostToolUse, UserPromptSubmit, Stop, SubagentStop**: 'block' OR undefined (no decision field)\n- **SessionStart/SessionEnd**: No decision field; use additionalContext only\n\n**Our hooks and their issues:**\n\n1. **SessionStart hook** (hooks/session-start.sh:25-32)\n   - ✅ CORRECT: Returns hookSpecificOutput with additionalContext, no decision field\n   \n2. **Stop hook** (hooks/stop/10-gentle-reminders.sh:85-86)\n   - ✅ CORRECT: Returns nothing (just exit 0), which is valid for non-blocking reminders\n   \n3. **PostToolUse hook** (hooks/post-tool-use/01-track-edits.sh:73,79,98,119)\n   - ❌ INCORRECT: Returns {\"decision\": \"approve\"} \n   - Should: Omit decision field entirely (just tracking edits, not blocking)\n   - Correct format: {} or {\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\"}}\n   \n4. **UserPromptSubmit hook** (hooks/user-prompt-submit/10-skill-activator.js:159,167,182,190,197)\n   - ❌ INCORRECT: Returns {\"decision\": \"approve\", \"additionalContext\": \"...\"}\n   - Should: Omit decision field (adding context, not blocking prompts)\n   - Correct format: {\"additionalContext\": \"...\"} or {\"hookSpecificOutput\": {\"hookEventName\": \"UserPromptSubmit\", \"additionalContext\": \"...\"}}\n\n**Why 'approve' is wrong:**\n- 'approve' is a deprecated legacy value that mapped to 'allow' for PreToolUse\n- For PostToolUse and UserPromptSubmit, 'approve' is not a valid decision\n- These hooks should either omit the decision field OR use 'block' if they want to halt execution\n\n**Evidence:**\n- Official docs: https://docs.claude.com/en/docs/claude-code/hooks\n- Research from hyperpowers:internet-researcher agent (detailed analysis)\n- Git history shows 'continue' was changed to 'approve' in 6aaceca, but both are incorrect\n\n## Solution Approach\n\n1. Remove decision field from PostToolUse hook (4 locations in hooks/post-tool-use/01-track-edits.sh)\n2. Remove decision field from UserPromptSubmit hook (5 locations in hooks/user-prompt-submit/10-skill-activator.js)  \n3. Update all documentation/examples to reflect correct response structure\n4. Keep SessionStart and Stop hooks as-is (already correct)","notes":"## Summary\n\nFixed hooks to use correct decision values per Claude Code specification.\n\n## Changes Made\n\n### 1. PostToolUse Hook (hooks/post-tool-use/01-track-edits.sh)\n- Removed invalid 'decision': 'approve' field (4 locations)\n- Now returns '{}' (empty object) - correct for non-blocking logging hooks\n\n### 2. UserPromptSubmit Hook (hooks/user-prompt-submit/10-skill-activator.js)\n- Removed invalid 'decision': 'approve' field (5 locations)\n- Now returns '{}' or '{\"additionalContext\": \"...\"}' - correct for context injection\n\n### 3. Test Files Updated\n- hooks/post-tool-use/test-hook.sh: Check for no decision field\n- hooks/user-prompt-submit/test-hook.sh: Check for no decision field\n- hooks/test/integration-test.sh: Updated expectations\n\n### 4. Documentation Updated\n- HOOKS.md: Updated output examples\n- skills/building-hooks/resources/hook-examples.md: Fixed all examples\n- skills/building-hooks/resources/hook-patterns.md: Fixed all patterns\n- skills/skills-auto-activation/resources/hook-implementation.md: Fixed expected output\n\n## Verification\n\nAll integration tests passing (13/13).","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-10-30T16:08:29.942365-04:00","updated_at":"2025-10-30T16:16:30.423079-04:00","closed_at":"2025-10-30T16:16:30.423079-04:00"}
